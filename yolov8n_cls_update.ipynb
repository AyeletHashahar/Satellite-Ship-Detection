{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sSExJJKusNB7",
        "outputId": "815393a9-2048-4ead-fdbf-3c81583156d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.103-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.103-py3-none-any.whl (994 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.103 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "metadata": {
        "id": "wVyBOkVsL2z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929046c9-c127-49e3-c737-b07a3e7ff873"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 2: Define the path to the directory containing ship and no-ship folders\n",
        "EXTRACT_PATH = \"/content/drive/MyDrive/archive\"   # Change if directory is elsewhere\n",
        "\n",
        "# Class folders\n",
        "SHIP_DIR = os.path.join(EXTRACT_PATH, \"ship\")\n",
        "NO_SHIP_DIR = os.path.join(EXTRACT_PATH, \"no-ship\")\n",
        "\n",
        "# Step 3: Collect all images with their labels\n",
        "all_images = []\n",
        "for img in os.listdir(SHIP_DIR):\n",
        "    all_images.append((os.path.join(SHIP_DIR, img), \"ship\"))\n",
        "for img in os.listdir(NO_SHIP_DIR):\n",
        "    all_images.append((os.path.join(NO_SHIP_DIR, img), \"no-ship\"))\n",
        "\n",
        "# Step 4: Create DataFrame from images\n",
        "df = pd.DataFrame(all_images, columns=[\"filepath\", \"label\"])\n",
        "\n",
        "# Step 5: Split into Train / Val / Test\n",
        "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
        "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"label\"], random_state=42)\n",
        "\n",
        "# Step 6: Create directories for YOLO\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for class_name in [\"ship\", \"no-ship\"]:\n",
        "        os.makedirs(f\"/content/yolo_data/{split}/{class_name}\", exist_ok=True)\n",
        "\n",
        "# Step 7: Copy files according to the split\n",
        "def process_split(df, split):\n",
        "    for _, row in df.iterrows():\n",
        "        class_name = row[\"label\"]\n",
        "        dest_dir = os.path.join(\"/content/yolo_data\", split, class_name)\n",
        "        shutil.copy(row[\"filepath\"], os.path.join(dest_dir, os.path.basename(row[\"filepath\"])))\n",
        "\n",
        "process_split(train_df, \"train\")\n",
        "process_split(val_df, \"val\")\n",
        "process_split(test_df, \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTjiawPL_9u6",
        "outputId": "c15f9287-2e13-4a5b-cb19-362dd187c4b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Step 8: Save filenames from each set (based on enhanced images)\n",
        "train_names = train_df[\"filepath\"].apply(os.path.basename).tolist()\n",
        "val_names = val_df[\"filepath\"].apply(os.path.basename).tolist()\n",
        "test_names = test_df[\"filepath\"].apply(os.path.basename).tolist()\n",
        "\n",
        "# Step 9: Extract ZIP file of original images (if not already done)\n",
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/archive2.zip\"  # ← Update if different\n",
        "extract_path = \"/content/original_data/archive2/archive2/archive2/archive2/\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "# After extraction - expecting structure: /content/original_data/ship + no-ship\n",
        "ORIG_SHIP_DIR = os.path.join(extract_path, \"ship\")\n",
        "ORIG_NO_SHIP_DIR = os.path.join(extract_path, \"no-ship\")\n",
        "\n",
        "# Step 10: Create directories for yolo_data_original\n",
        "base_output = \"/content/yolo_data_original2\"\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    for cls in [\"ship\", \"no-ship\"]:\n",
        "        os.makedirs(os.path.join(base_output, split, cls), exist_ok=True)\n",
        "\n",
        "# Step 11: Helper to decode original filenames from enhanced names\n",
        "def extract_index(filename):\n",
        "    match = re.search(r'_(\\d{6})_', filename)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def build_original_filename(enhanced_name):\n",
        "    # Extract category from name\n",
        "    if enhanced_name.startswith(\"ship\"):\n",
        "        prefix = \"ship\"\n",
        "    elif enhanced_name.startswith(\"no-ship\"):\n",
        "        prefix = \"no-ship\"\n",
        "    else:\n",
        "        return None, None  # No category identified\n",
        "\n",
        "    # Extract index\n",
        "    index = extract_index(enhanced_name)\n",
        "    if index:\n",
        "        filename = f\"{prefix}_{index}_original.png\"\n",
        "        return filename, prefix\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "# Step 12: Copy original images according to names\n",
        "def copy_matching_images(enhanced_file_list, split_name):\n",
        "    for enhanced_name in enhanced_file_list:\n",
        "        orig_name, cls = build_original_filename(enhanced_name)\n",
        "        if orig_name and cls:\n",
        "            src_dir = ORIG_SHIP_DIR if cls == \"ship\" else ORIG_NO_SHIP_DIR\n",
        "            dest_dir = os.path.join(base_output, split_name, cls)\n",
        "\n",
        "            src_path = os.path.join(src_dir, orig_name)\n",
        "            if os.path.exists(src_path):\n",
        "                shutil.copy(src_path, os.path.join(dest_dir, orig_name))\n",
        "\n",
        "copy_matching_images(train_names, \"train\")\n",
        "copy_matching_images(val_names, \"val\")\n",
        "copy_matching_images(test_names, \"test\")"
      ],
      "metadata": {
        "id": "omq3Ewk5R6Kb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Number of folds to use\n",
        "NUM_FOLDS = 10\n",
        "# Number of training epochs\n",
        "NUM_EPOCHS = 10\n",
        "# Size of the separate test set (10%)\n",
        "TEST_SIZE = 0.1\n",
        "\n",
        "def prepare_data_for_kfold(enhanced_dir, original_dir):\n",
        "    \"\"\"Prepare data for k-fold validation\"\"\"\n",
        "\n",
        "    # Collect images from all sets (train, val, test) into one place\n",
        "    enhanced_ship_images = []\n",
        "    enhanced_noship_images = []\n",
        "    original_ship_images = []\n",
        "    original_noship_images = []\n",
        "\n",
        "    # For enhanced data\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        ship_path = os.path.join(enhanced_dir, split, 'ship')\n",
        "        noship_path = os.path.join(enhanced_dir, split, 'no-ship')\n",
        "\n",
        "        if os.path.exists(ship_path):\n",
        "            for img in os.listdir(ship_path):\n",
        "                enhanced_ship_images.append(os.path.join(ship_path, img))\n",
        "\n",
        "        if os.path.exists(noship_path):\n",
        "            for img in os.listdir(noship_path):\n",
        "                enhanced_noship_images.append(os.path.join(noship_path, img))\n",
        "\n",
        "    # For original data\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        ship_path = os.path.join(original_dir, split, 'ship')\n",
        "        noship_path = os.path.join(original_dir, split, 'no-ship')\n",
        "\n",
        "        if os.path.exists(ship_path):\n",
        "            for img in os.listdir(ship_path):\n",
        "                original_ship_images.append(os.path.join(ship_path, img))\n",
        "\n",
        "        if os.path.exists(noship_path):\n",
        "            for img in os.listdir(noship_path):\n",
        "                original_noship_images.append(os.path.join(noship_path, img))\n",
        "\n",
        "    # Create DataFrame with paths and labels\n",
        "    enhanced_data = pd.DataFrame({\n",
        "        'filepath': enhanced_ship_images + enhanced_noship_images,\n",
        "        'label': ['ship'] * len(enhanced_ship_images) + ['no-ship'] * len(enhanced_noship_images)\n",
        "    })\n",
        "\n",
        "    original_data = pd.DataFrame({\n",
        "        'filepath': original_ship_images + original_noship_images,\n",
        "        'label': ['ship'] * len(original_ship_images) + ['no-ship'] * len(original_noship_images)\n",
        "    })\n",
        "\n",
        "    return enhanced_data, original_data\n",
        "\n",
        "def split_train_test(data_df, test_size=TEST_SIZE, random_state=42):\n",
        "    \"\"\"Split data into training and test sets\"\"\"\n",
        "\n",
        "    # Split while preserving class distribution\n",
        "    train_df, test_df = train_test_split(\n",
        "        data_df,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state,\n",
        "        stratify=data_df['label']  # Maintains the same ship/no-ship ratio in both sets\n",
        "    )\n",
        "\n",
        "    print(f\"  Train set: {len(train_df)} images\")\n",
        "    print(f\"  Test set: {len(test_df)} images\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def perform_kfold_validation(train_df, data_type='enhanced', img_size=320):\n",
        "    \"\"\"Perform K-fold validation on the training set\"\"\"\n",
        "\n",
        "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "    # Store results for later analysis\n",
        "    fold_results = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n",
        "        print(f\"\\n=== Fold {fold+1}/{NUM_FOLDS} for {data_type} data ===\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create directories for current fold\n",
        "        fold_dir = f\"/content/kfold_{data_type}/fold_{fold+1}\"\n",
        "\n",
        "        # Remove directory if it exists\n",
        "        if os.path.exists(fold_dir):\n",
        "            shutil.rmtree(fold_dir)\n",
        "\n",
        "        for class_name in ['ship', 'no-ship']:\n",
        "            for split in ['train', 'val']:\n",
        "                os.makedirs(f\"{fold_dir}/{split}/{class_name}\", exist_ok=True)\n",
        "\n",
        "        # Split into train and validation\n",
        "        fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
        "        fold_val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "        print(f\"  Fold {fold+1} - Train: {len(fold_train_df)}, Validation: {len(fold_val_df)}\")\n",
        "\n",
        "        # Copy files to appropriate directories\n",
        "        for _, row in fold_train_df.iterrows():\n",
        "            dest_path = f\"{fold_dir}/train/{row['label']}/{os.path.basename(row['filepath'])}\"\n",
        "            shutil.copy(row['filepath'], dest_path)\n",
        "\n",
        "        for _, row in fold_val_df.iterrows():\n",
        "            dest_path = f\"{fold_dir}/val/{row['label']}/{os.path.basename(row['filepath'])}\"\n",
        "            shutil.copy(row['filepath'], dest_path)\n",
        "\n",
        "        # Train the model\n",
        "        model = YOLO(\"yolov8n-cls.pt\")\n",
        "\n",
        "        # Set training parameters\n",
        "        results = model.train(\n",
        "            data=fold_dir,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            imgsz=img_size,\n",
        "            verbose=False,\n",
        "            project=f\"/content/runs/kfold_{data_type}\",\n",
        "            name=f\"fold_{fold+1}\"\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        metrics = model.val()\n",
        "\n",
        "        # Save results\n",
        "        fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'accuracy': metrics.top1,\n",
        "            'val_indices': val_idx,  # Store indices for unified predictions\n",
        "            'model_path': f\"/content/runs/kfold_{data_type}/fold_{fold+1}/weights/best.pt\"\n",
        "        })\n",
        "\n",
        "        end_time = time.time()\n",
        "        fold_time = end_time - start_time\n",
        "\n",
        "        print(f\"Fold {fold+1} completed in {fold_time:.2f} seconds\")\n",
        "        print(f\"Fold {fold+1} accuracy: {metrics.top1:.4f}\")\n",
        "\n",
        "    # Calculate statistics\n",
        "    accuracies = [result['accuracy'] for result in fold_results]\n",
        "    mean_accuracy = np.mean(accuracies)\n",
        "    std_accuracy = np.std(accuracies)\n",
        "\n",
        "    print(f\"\\n=== {data_type.upper()} DATA K-FOLD RESULTS ===\")\n",
        "    print(f\"Mean accuracy: {mean_accuracy:.4f}\")\n",
        "    print(f\"Standard deviation: {std_accuracy:.4f}\")\n",
        "    print(f\"Accuracy per fold: {accuracies}\")\n",
        "\n",
        "    return fold_results, mean_accuracy, std_accuracy\n",
        "\n",
        "def evaluate_model_on_test_set(best_model_path, test_df, class_names, data_type):\n",
        "    \"\"\"Evaluate the best model on the separate test set\"\"\"\n",
        "\n",
        "    print(f\"\\nEvaluating best model for {data_type} data on the test set...\")\n",
        "\n",
        "    # Load the best model\n",
        "    model = YOLO(best_model_path)\n",
        "\n",
        "    # Predict on test set\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    confidences = []\n",
        "\n",
        "    for _, row in test_df.iterrows():\n",
        "        result = model.predict(row['filepath'], verbose=False)[0]\n",
        "        pred_class = result.names[result.probs.top1]\n",
        "\n",
        "        predictions.append(pred_class)\n",
        "        true_labels.append(row['label'])\n",
        "        confidences.append(float(result.probs.top1conf))\n",
        "\n",
        "    # Analyze results\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    class_report = classification_report(true_labels, predictions, target_names=class_names)\n",
        "    cm = confusion_matrix(true_labels, predictions, labels=class_names)\n",
        "\n",
        "    print(f\"Test Set Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"\\nClassification Report:\\n{class_report}\")\n",
        "\n",
        "    # Visualize confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names,\n",
        "                yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(f'Confusion Matrix for {data_type.capitalize()} Data (Test Set)')\n",
        "    plt.savefig(f'/content/{data_type}_confusion_matrix.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Analyze misclassified samples\n",
        "    error_df = pd.DataFrame({\n",
        "        'filepath': test_df['filepath'].values,\n",
        "        'true_label': true_labels,\n",
        "        'predicted': predictions,\n",
        "        'confidence': confidences\n",
        "    })\n",
        "\n",
        "    error_df['correct'] = error_df['true_label'] == error_df['predicted']\n",
        "    misclassified = error_df[~error_df['correct']].sort_values('confidence', ascending=False)\n",
        "\n",
        "    print(f\"Total test samples: {len(test_df)}\")\n",
        "    print(f\"Correct predictions: {len(error_df[error_df['correct']])}\")\n",
        "    print(f\"Misclassified samples: {len(misclassified)}\")\n",
        "\n",
        "    # Save list of misclassified images\n",
        "    if len(misclassified) > 0:\n",
        "        misclassified.to_csv(f'/content/{data_type}_misclassified.csv', index=False)\n",
        "        print(f\"Saved misclassified samples to: /content/{data_type}_misclassified.csv\")\n",
        "\n",
        "    return accuracy, class_report, cm, misclassified\n",
        "\n",
        "def find_best_model(fold_results):\n",
        "    \"\"\"Find the best model from all folds\"\"\"\n",
        "    return max(fold_results, key=lambda x: x['accuracy'])\n",
        "\n",
        "def compare_models(enhanced_results, original_results, enhanced_test_acc, original_test_acc):\n",
        "    \"\"\"Compare the models\"\"\"\n",
        "\n",
        "    enhanced_cv_acc = enhanced_results[1]  # Mean accuracy from K-fold\n",
        "    original_cv_acc = original_results[1]  # Mean accuracy from K-fold\n",
        "    enhanced_cv_std = enhanced_results[2]  # Standard deviation from K-fold\n",
        "    original_cv_std = original_results[2]  # Standard deviation from K-fold\n",
        "\n",
        "    print(\"\\n=== MODEL COMPARISON ===\")\n",
        "    print(f\"Enhanced Resolution Model:\")\n",
        "    print(f\"  - Cross-validation Accuracy: {enhanced_cv_acc:.4f} (±{enhanced_cv_std:.4f})\")\n",
        "    print(f\"  - Test Set Accuracy: {enhanced_test_acc:.4f}\")\n",
        "    print(f\"Original Resolution Model:\")\n",
        "    print(f\"  - Cross-validation Accuracy: {original_cv_acc:.4f} (±{original_cv_std:.4f})\")\n",
        "    print(f\"  - Test Set Accuracy: {original_test_acc:.4f}\")\n",
        "\n",
        "    # Visualization of comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Data for comparison\n",
        "    models = ['Enhanced - CV', 'Enhanced - Test', 'Original - CV', 'Original - Test']\n",
        "    accuracies = [enhanced_cv_acc, enhanced_test_acc, original_cv_acc, original_test_acc]\n",
        "    errors = [enhanced_cv_std, 0, original_cv_std, 0]  # No std dev for test set\n",
        "    colors = ['#3498db', '#2980b9', '#2ecc71', '#27ae60']\n",
        "\n",
        "    # Create chart\n",
        "    bars = plt.bar(models, accuracies, yerr=errors, capsize=10, color=colors)\n",
        "\n",
        "    # Add labels\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model Comparison: Enhanced vs. Original Resolution')\n",
        "    plt.ylim(max(0.9, min(accuracies) - 0.05), min(1.0, max(accuracies) + 0.05))  # Adjust Y-axis limits\n",
        "\n",
        "    # Add values above bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                f'{height:.4f}', ha='center', va='bottom')\n",
        "\n",
        "    plt.savefig('/content/model_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Statistical comparison - is the difference significant\n",
        "    if enhanced_test_acc > original_test_acc:\n",
        "        diff_pct = ((enhanced_test_acc - original_test_acc) / original_test_acc) * 100\n",
        "        print(f\"\\nEnhanced resolution model performs {diff_pct:.2f}% better on the test set.\")\n",
        "    elif original_test_acc > enhanced_test_acc:\n",
        "        diff_pct = ((original_test_acc - enhanced_test_acc) / enhanced_test_acc) * 100\n",
        "        print(f\"\\nOriginal resolution model performs {diff_pct:.2f}% better on the test set.\")\n",
        "    else:\n",
        "        print(\"\\nBoth models perform equally on the test set.\")\n",
        "\n",
        "# Main function for evaluation\n",
        "def main():\n",
        "    # Measure runtime\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Define paths\n",
        "    enhanced_data_dir = \"/content/yolo_data\"\n",
        "    original_data_dir = \"/content/yolo_data_original2\"\n",
        "\n",
        "    # Define class names\n",
        "    class_names = ['no-ship', 'ship']\n",
        "\n",
        "    print(\"Preparing data for K-fold validation...\")\n",
        "    enhanced_data, original_data = prepare_data_for_kfold(enhanced_data_dir, original_data_dir)\n",
        "\n",
        "    print(f\"Enhanced data: {len(enhanced_data)} images\")\n",
        "    print(f\"Original data: {len(original_data)} images\")\n",
        "\n",
        "    # 1. Split into training and test sets\n",
        "    print(\"\\nSplitting enhanced data into train and test sets...\")\n",
        "    enhanced_train_df, enhanced_test_df = split_train_test(enhanced_data)\n",
        "\n",
        "    print(\"\\nSplitting original data into train and test sets...\")\n",
        "    original_train_df, original_test_df = split_train_test(original_data)\n",
        "\n",
        "    # 2. Perform K-fold validation on training set\n",
        "    print(\"\\nPerforming K-fold validation for enhanced resolution data...\")\n",
        "    enhanced_results = perform_kfold_validation(enhanced_train_df, data_type='enhanced', img_size=320)\n",
        "\n",
        "    print(\"\\nPerforming K-fold validation for original resolution data...\")\n",
        "    original_results = perform_kfold_validation(original_train_df, data_type='original', img_size=80)\n",
        "\n",
        "    # 3. Find the best model\n",
        "    best_enhanced_model = find_best_model(enhanced_results[0])\n",
        "    best_original_model = find_best_model(original_results[0])\n",
        "\n",
        "    print(f\"\\nBest enhanced model: Fold {best_enhanced_model['fold']} with accuracy {best_enhanced_model['accuracy']:.4f}\")\n",
        "    print(f\"Best original model: Fold {best_original_model['fold']} with accuracy {best_original_model['accuracy']:.4f}\")\n",
        "\n",
        "    # 4. Evaluate best models on separate test set\n",
        "    enhanced_test_results = evaluate_model_on_test_set(\n",
        "        best_enhanced_model['model_path'],\n",
        "        enhanced_test_df,\n",
        "        class_names,\n",
        "        'enhanced'\n",
        "    )\n",
        "\n",
        "    original_test_results = evaluate_model_on_test_set(\n",
        "        best_original_model['model_path'],\n",
        "        original_test_df,\n",
        "        class_names,\n",
        "        'original'\n",
        "    )\n",
        "\n",
        "    # 5. Compare models\n",
        "    compare_models(\n",
        "        enhanced_results,\n",
        "        original_results,\n",
        "        enhanced_test_results[0],  # Accuracy on test set for enhanced model\n",
        "        original_test_results[0]   # Accuracy on test set for original model\n",
        "    )\n",
        "\n",
        "    # Summarize runtime\n",
        "    total_end_time = time.time()\n",
        "    total_time = total_end_time - total_start_time\n",
        "\n",
        "    print(f\"\\nComplete evaluation process finished in {total_time/60:.2f} minutes\")\n",
        "    print(\"\\nK-fold validation complete! Check the output files for detailed results.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8DBYAcU-9CH",
        "outputId": "c75b7bce-8ef3-47ce-b3b9-602d88158738"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data for K-fold validation...\n",
            "Enhanced data: 3860 images\n",
            "Original data: 3858 images\n",
            "\n",
            "Splitting enhanced data into train and test sets...\n",
            "  Train set: 3474 images\n",
            "  Test set: 386 images\n",
            "\n",
            "Splitting original data into train and test sets...\n",
            "  Train set: 3472 images\n",
            "  Test set: 386 images\n",
            "\n",
            "Performing K-fold validation for enhanced resolution data...\n",
            "\n",
            "=== Fold 1/10 for enhanced data ===\n",
            "  Fold 1 - Train: 3126, Validation: 348\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.31M/5.31M [00:00<00:00, 394MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_1, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_1, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_1\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_1/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_1/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_1', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 353MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_1/train... 3126 images, 0 corrupt: 100%|██████████| 3126/3126 [00:05<00:00, 567.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_1/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_1/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<00:00, 502.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_1/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_1\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.445G     0.5531         16        320:  16%|█▋        | 32/196 [00:02<00:07, 21.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.445G     0.4795         16        320:  33%|███▎      | 65/196 [00:03<00:05, 26.08it/s]\n",
            "100%|██████████| 755k/755k [00:00<00:00, 90.2MB/s]\n",
            "       1/10     0.447G     0.3006          6        320: 100%|██████████| 196/196 [00:08<00:00, 23.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 35.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.963          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.555G     0.1894          6        320: 100%|██████████| 196/196 [00:06<00:00, 28.63it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 39.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.966          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.562G     0.1475          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 50.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.98          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      0.57G     0.1394          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 44.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.968          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      0.58G      0.104          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.588G     0.1084          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 64.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.596G     0.0826          6        320: 100%|██████████| 196/196 [00:06<00:00, 28.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 55.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.604G    0.06604          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.98          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.613G    0.05894          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 42.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.621G    0.04597          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 39.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_1/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_1/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_1/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_1/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_1/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 35.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n",
            "Speed: 0.2ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_1\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_1/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_1/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_1/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 32.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n",
            "Speed: 0.4ms preprocess, 0.9ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_12\u001b[0m\n",
            "Fold 1 completed in 99.22 seconds\n",
            "Fold 1 accuracy: 0.9914\n",
            "\n",
            "=== Fold 2/10 for enhanced data ===\n",
            "  Fold 2 - Train: 3126, Validation: 348\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_2, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_2/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_2/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_2/train... 3126 images, 0 corrupt: 100%|██████████| 3126/3126 [00:05<00:00, 574.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_2/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_2/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<00:00, 540.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_2/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.451G     0.3162          6        320: 100%|██████████| 196/196 [00:07<00:00, 25.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 63.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.96          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.488G     0.1627          6        320: 100%|██████████| 196/196 [00:07<00:00, 27.90it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.488G     0.1458          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 54.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.957          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      0.49G     0.1519          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.498G     0.1147          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.22it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 53.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.506G     0.1071          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.27it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.516G    0.08708          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.09it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 52.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.521G    0.06422          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 54.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.531G    0.06514          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 50.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.539G    0.05599          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.13it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n",
            "\n",
            "10 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_2/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_2/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_2/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_2/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_2/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 33.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.2ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_2\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_2/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_2/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_2/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 40.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.2ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_22\u001b[0m\n",
            "Fold 2 completed in 87.33 seconds\n",
            "Fold 2 accuracy: 0.9971\n",
            "\n",
            "=== Fold 3/10 for enhanced data ===\n",
            "  Fold 3 - Train: 3126, Validation: 348\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_3, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_3, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_3\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_3/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_3/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_3', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_3/train... 3126 images, 0 corrupt: 100%|██████████| 3126/3126 [00:05<00:00, 577.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_3/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_3/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<00:00, 475.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_3/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_3\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.484G     0.3135          6        320: 100%|██████████| 196/196 [00:07<00:00, 24.68it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.922          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.521G     0.1677          6        320: 100%|██████████| 196/196 [00:06<00:00, 28.44it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.948          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.521G     0.1768          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.52it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.521G     0.1415          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.10it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 49.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.521G     0.1105          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.33it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.974          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.521G     0.1023          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 53.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.96          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.521G     0.0768          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 66.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.523G    0.06729          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.99it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.963          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.531G    0.06489          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 66.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.539G    0.04791          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 50.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_3/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_3/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_3/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_3/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_3/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 34.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_3\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_3/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_3/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_3/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 39.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n",
            "Speed: 0.3ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_32\u001b[0m\n",
            "Fold 3 completed in 86.74 seconds\n",
            "Fold 3 accuracy: 0.9885\n",
            "\n",
            "=== Fold 4/10 for enhanced data ===\n",
            "  Fold 4 - Train: 3126, Validation: 348\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_4, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_4, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_4\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_4/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_4/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_4', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_4/train... 3126 images, 0 corrupt: 100%|██████████| 3126/3126 [00:05<00:00, 568.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_4/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_4/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<00:00, 623.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_4/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.469G     0.3074          6        320: 100%|██████████| 196/196 [00:07<00:00, 25.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.957          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.506G     0.1765          6        320: 100%|██████████| 196/196 [00:07<00:00, 27.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.96          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.506G     0.1617          6        320: 100%|██████████| 196/196 [00:06<00:00, 28.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.96          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.506G     0.1402          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 70.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.971          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.506G     0.1131          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.76it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 53.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.506G    0.08642          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.10it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.506G     0.0685          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.512G    0.06946          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.46it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.52G    0.06463          6        320: 100%|██████████| 196/196 [00:06<00:00, 29.68it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 53.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.527G    0.05355          6        320: 100%|██████████| 196/196 [00:06<00:00, 30.19it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_4/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_4/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_4/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_4/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_4/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 39.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n",
            "Speed: 0.2ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_4\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_4/train... found 3126 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_4/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_4/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 35.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n",
            "Speed: 0.3ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_42\u001b[0m\n",
            "Fold 4 completed in 87.38 seconds\n",
            "Fold 4 accuracy: 0.9885\n",
            "\n",
            "=== Fold 5/10 for enhanced data ===\n",
            "  Fold 5 - Train: 3127, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_5, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_5, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_5\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_5/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_5/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_5', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_5/train... 3127 images, 0 corrupt: 100%|██████████| 3127/3127 [00:05<00:00, 580.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_5/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_5/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 493.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_5/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_5\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.488G     0.3106          7        320: 100%|██████████| 196/196 [00:08<00:00, 23.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 49.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.916          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.525G     0.1738          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 51.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.525G     0.1693          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.72it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.931          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.525G     0.1391          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 46.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.968          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.525G     0.1205          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 52.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.525G    0.08316          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 66.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.525G    0.08061          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.533G    0.07256          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.98          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.541G    0.06622          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 65.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.549G    0.05295          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.15it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 55.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_5/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_5/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_5/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_5/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_5/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 36.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_5\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_5/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_5/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_5/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 35.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.3ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_52\u001b[0m\n",
            "Fold 5 completed in 87.53 seconds\n",
            "Fold 5 accuracy: 0.9942\n",
            "\n",
            "=== Fold 6/10 for enhanced data ===\n",
            "  Fold 6 - Train: 3127, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_6, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_6, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_6\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_6/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_6/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_6', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_6/train... 3127 images, 0 corrupt: 100%|██████████| 3127/3127 [00:05<00:00, 555.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_6/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_6/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 499.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_6/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_6\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.479G     0.3032          7        320: 100%|██████████| 196/196 [00:07<00:00, 25.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.937          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.516G     0.2017          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.10it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.965          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.516G     0.1503          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.78it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 52.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.965          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.516G     0.1276          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.51it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 54.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.516G     0.1177          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.29it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 51.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.516G    0.08934          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 44.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.98          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      0.52G    0.08129          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 65.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.527G    0.06455          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.09it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.535G    0.06827          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 66.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.543G    0.05862          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 55.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "\n",
            "10 epochs completed in 0.020 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_6/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_6/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_6/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_6/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_6/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 36.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_6\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_6/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_6/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_6/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 33.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.5ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_62\u001b[0m\n",
            "Fold 6 completed in 88.29 seconds\n",
            "Fold 6 accuracy: 0.9971\n",
            "\n",
            "=== Fold 7/10 for enhanced data ===\n",
            "  Fold 7 - Train: 3127, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_7, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_7, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_7\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_7/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_7/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_7', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_7/train... 3127 images, 0 corrupt: 100%|██████████| 3127/3127 [00:05<00:00, 577.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_7/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_7/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 471.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_7/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_7\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.494G     0.3133          7        320: 100%|██████████| 196/196 [00:08<00:00, 24.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 63.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.954          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.531G     0.1766          7        320: 100%|██████████| 196/196 [00:07<00:00, 27.30it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 69.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.531G     0.1717          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.531G      0.135          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.93it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.531G     0.1187          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.87it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 55.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.963          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.531G     0.0998          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.539G     0.0765          7        320: 100%|██████████| 196/196 [00:06<00:00, 30.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 65.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.547G    0.06976          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.555G    0.06941          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 52.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.562G    0.05812          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 56.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_7/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_7/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_7/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_7/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_7/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 35.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_7\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_7/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_7/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_7/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 35.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.4ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_72\u001b[0m\n",
            "Fold 7 completed in 88.77 seconds\n",
            "Fold 7 accuracy: 0.9942\n",
            "\n",
            "=== Fold 8/10 for enhanced data ===\n",
            "  Fold 8 - Train: 3127, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_8, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_8, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_8\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_8/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_8/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_8', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_8/train... 3127 images, 0 corrupt: 100%|██████████| 3127/3127 [00:05<00:00, 576.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_8/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_8/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 488.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_8/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_8\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.496G     0.3143          7        320: 100%|██████████| 196/196 [00:08<00:00, 23.06it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.939          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.533G     0.1976          7        320: 100%|██████████| 196/196 [00:07<00:00, 27.95it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.533G     0.1493          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.68it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 55.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.533G     0.1522          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 48.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.533G     0.1272          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 49.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.533G    0.07966          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.541G    0.08923          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 64.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.547G    0.06346          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.85it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 63.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.557G    0.06228          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.562G    0.05787          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_8/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_8/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_8/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_8/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_8/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 36.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_8\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_8/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_8/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_8/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 41.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.2ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_82\u001b[0m\n",
            "Fold 8 completed in 89.32 seconds\n",
            "Fold 8 accuracy: 0.9942\n",
            "\n",
            "=== Fold 9/10 for enhanced data ===\n",
            "  Fold 9 - Train: 3127, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_9, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_9, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_9\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_9/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_9/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_9', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_9/train... 3127 images, 0 corrupt: 100%|██████████| 3127/3127 [00:05<00:00, 554.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_9/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_9/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 494.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_9/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_9\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.488G     0.3044          7        320: 100%|██████████| 196/196 [00:08<00:00, 24.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.525G     0.1725          7        320: 100%|██████████| 196/196 [00:07<00:00, 27.66it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.525G     0.1622          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.19it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 52.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.957          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.525G     0.1422          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.525G     0.1237          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.88it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 48.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.525G    0.07308          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 60.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.531G    0.06838          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 65.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.539G    0.06087          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.547G    0.06257          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.61it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 57.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.555G    0.05183          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.28it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_9/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_9/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_9/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_9/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_9/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 32.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.2ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_9\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_9/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_9/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_9/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 37.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.4ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_92\u001b[0m\n",
            "Fold 9 completed in 89.75 seconds\n",
            "Fold 9 accuracy: 0.9971\n",
            "\n",
            "=== Fold 10/10 for enhanced data ===\n",
            "  Fold 10 - Train: 3127, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_enhanced/fold_10, epochs=10, time=None, patience=100, batch=16, imgsz=320, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_enhanced, name=fold_10, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_enhanced/fold_10\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_10/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_10/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_enhanced/fold_10', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_enhanced/fold_10/train... 3127 images, 0 corrupt: 100%|██████████| 3127/3127 [00:05<00:00, 573.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_enhanced/fold_10/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_10/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 561.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_enhanced/fold_10/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 320 train, 320 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_enhanced/fold_10\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.492G     0.3136          7        320: 100%|██████████| 196/196 [00:07<00:00, 25.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 56.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.965          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.529G     0.1736          7        320: 100%|██████████| 196/196 [00:07<00:00, 27.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 59.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.957          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.529G     0.1678          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 64.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.529G     0.1337          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.75it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 63.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.529G     0.1174          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.529G    0.08245          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.529G    0.07046          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.30it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 61.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.533G    0.07298          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.81it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 58.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.541G    0.08406          7        320: 100%|██████████| 196/196 [00:06<00:00, 28.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.549G    0.06184          7        320: 100%|██████████| 196/196 [00:06<00:00, 29.05it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 52.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_10/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_enhanced/fold_10/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_enhanced/fold_10/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_10/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_10/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 34.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.2ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_10\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_enhanced/fold_10/train... found 3127 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_enhanced/fold_10/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_enhanced/fold_10/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 35.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.3ms preprocess, 0.5ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_enhanced/fold_102\u001b[0m\n",
            "Fold 10 completed in 89.28 seconds\n",
            "Fold 10 accuracy: 0.9971\n",
            "\n",
            "=== ENHANCED DATA K-FOLD RESULTS ===\n",
            "Mean accuracy: 0.9940\n",
            "Standard deviation: 0.0033\n",
            "Accuracy per fold: [0.9913793206214905, 0.9971264600753784, 0.9885057210922241, 0.9885057210922241, 0.9942362904548645, 0.9971181750297546, 0.9942362904548645, 0.9942362904548645, 0.9971181750297546, 0.9971181750297546]\n",
            "\n",
            "Performing K-fold validation for original resolution data...\n",
            "\n",
            "=== Fold 1/10 for original data ===\n",
            "  Fold 1 - Train: 3124, Validation: 348\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_1, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_1, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_1\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_1/train... found 3124 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_1/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_1', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_1/train... 3124 images, 0 corrupt: 100%|██████████| 3124/3124 [00:00<00:00, 3667.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_1/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_1/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<00:00, 2696.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_1/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_1\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      0.34G     0.3022          4         96: 100%|██████████| 196/196 [00:06<00:00, 30.63it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 62.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      0.34G     0.1605          4         96: 100%|██████████| 196/196 [00:05<00:00, 36.89it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 130.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      0.34G     0.1369          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      0.34G     0.1345          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 113.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      0.34G     0.1043          4         96: 100%|██████████| 196/196 [00:04<00:00, 40.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.966          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      0.34G     0.1078          4         96: 100%|██████████| 196/196 [00:05<00:00, 38.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      0.34G    0.09398          4         96: 100%|██████████| 196/196 [00:04<00:00, 40.41it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 137.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      0.34G    0.06685          4         96: 100%|██████████| 196/196 [00:04<00:00, 40.81it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 100.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.348G    0.06043          4         96: 100%|██████████| 196/196 [00:05<00:00, 39.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 122.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.355G    0.06705          4         96: 100%|██████████| 196/196 [00:05<00:00, 39.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 107.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_1/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_1/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_1/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_1/train... found 3124 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_1/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 71.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.0ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_1\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_1/train... found 3124 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_1/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_1/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 84.04it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_12\u001b[0m\n",
            "Fold 1 completed in 63.42 seconds\n",
            "Fold 1 accuracy: 0.9943\n",
            "\n",
            "=== Fold 2/10 for original data ===\n",
            "  Fold 2 - Train: 3124, Validation: 348\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_2, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_2/train... found 3124 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_2/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_2/train... 3124 images, 0 corrupt: 100%|██████████| 3124/3124 [00:00<00:00, 3575.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_2/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_2/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<00:00, 2521.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_2/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      0.24G     0.3027          4         96: 100%|██████████| 196/196 [00:06<00:00, 32.19it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 99.17it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.968          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      0.24G     0.1707          4         96: 100%|██████████| 196/196 [00:05<00:00, 36.74it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 136.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.963          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      0.24G     0.1276          4         96: 100%|██████████| 196/196 [00:05<00:00, 39.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 108.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.963          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      0.24G     0.1373          4         96: 100%|██████████| 196/196 [00:05<00:00, 37.73it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 113.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.971          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      0.24G     0.1068          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      0.24G    0.08928          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.72it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      0.24G    0.08488          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.34it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      0.24G    0.07098          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 127.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.989          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.244G    0.05876          4         96: 100%|██████████| 196/196 [00:04<00:00, 39.51it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 137.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.252G    0.05659          4         96: 100%|██████████| 196/196 [00:04<00:00, 40.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 106.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_2/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_2/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_2/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_2/train... found 3124 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_2/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 71.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_2\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_2/train... found 3124 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_2/val... found 348 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_2/val... 348 images, 0 corrupt: 100%|██████████| 348/348 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 81.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_22\u001b[0m\n",
            "Fold 2 completed in 62.99 seconds\n",
            "Fold 2 accuracy: 0.9943\n",
            "\n",
            "=== Fold 3/10 for original data ===\n",
            "  Fold 3 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_3, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_3, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_3\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_3/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_3/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_3', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_3/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3578.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_3/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_3/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2553.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_3/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_3\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.248G     0.3185          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 89.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.248G      0.155          5         96: 100%|██████████| 196/196 [00:05<00:00, 36.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.248G     0.1368          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.82it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 102.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.98          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.248G     0.1365          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 134.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.248G     0.1089          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.96it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 99.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.248G    0.08891          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.46it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 106.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.248G    0.08767          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 126.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.248G    0.07363          5         96: 100%|██████████| 196/196 [00:04<00:00, 40.39it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 111.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.25G    0.06996          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 119.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.258G     0.0603          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.66it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_3/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_3/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_3/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_3/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_3/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 72.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_3\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_3/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_3/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_3/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 69.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n",
            "Speed: 0.0ms preprocess, 0.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_32\u001b[0m\n",
            "Fold 3 completed in 63.22 seconds\n",
            "Fold 3 accuracy: 0.9942\n",
            "\n",
            "=== Fold 4/10 for original data ===\n",
            "  Fold 4 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_4, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_4, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_4\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_4/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_4/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_4', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_4/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3525.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_4/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_4/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2614.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_4/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_4\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.242G      0.301          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.10it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 131.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.242G     0.1533          5         96: 100%|██████████| 196/196 [00:05<00:00, 36.34it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 124.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.242G      0.168          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 123.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.242G     0.1312          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.08it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 112.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.242G     0.0967          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 123.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.242G     0.0883          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.50it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.242G    0.08473          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.17it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.242G    0.06741          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 98.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.25G    0.07464          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.77it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.258G    0.05722          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.42it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 121.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "\n",
            "10 epochs completed in 0.016 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_4/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_4/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_4/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_4/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_4/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_4\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_4/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_4/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_4/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 78.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_42\u001b[0m\n",
            "Fold 4 completed in 64.31 seconds\n",
            "Fold 4 accuracy: 1.0000\n",
            "\n",
            "=== Fold 5/10 for original data ===\n",
            "  Fold 5 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_5, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_5, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_5\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_5/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_5/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_5', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_5/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3596.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_5/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_5/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2814.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_5/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_5\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.244G      0.301          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.12it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 90.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.244G     0.1546          5         96: 100%|██████████| 196/196 [00:05<00:00, 35.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 134.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.244G     0.1616          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.63it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.244G     0.1515          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.71it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 129.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.244G     0.1182          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.81it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.244G    0.09357          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 99.70it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.244G    0.08153          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.244G    0.07723          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.83it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 96.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.25G    0.07572          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 128.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.258G    0.06315          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.94it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 117.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_5/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_5/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_5/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_5/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_5/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 76.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_5\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_5/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_5/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_5/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 81.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_52\u001b[0m\n",
            "Fold 5 completed in 63.53 seconds\n",
            "Fold 5 accuracy: 1.0000\n",
            "\n",
            "=== Fold 6/10 for original data ===\n",
            "  Fold 6 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_6, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_6, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_6\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_6/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_6/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_6', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_6/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3565.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_6/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_6/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2535.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_6/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_6\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      0.24G       0.31          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      0.24G     0.1479          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 137.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      0.24G     0.1679          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.98it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 114.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      0.24G     0.1274          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.24it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 115.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      0.24G     0.1127          5         96: 100%|██████████| 196/196 [00:05<00:00, 39.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 118.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      0.24G    0.09723          5         96: 100%|██████████| 196/196 [00:05<00:00, 39.13it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 102.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      0.24G    0.07939          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 107.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.242G    0.07953          5         96: 100%|██████████| 196/196 [00:04<00:00, 40.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 130.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.25G    0.06317          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.25it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 112.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.258G    0.05945          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.86it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 111.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_6/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_6/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_6/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_6/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_6/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 65.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_6\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_6/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_6/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_6/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 83.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_62\u001b[0m\n",
            "Fold 6 completed in 63.33 seconds\n",
            "Fold 6 accuracy: 0.9971\n",
            "\n",
            "=== Fold 7/10 for original data ===\n",
            "  Fold 7 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_7, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_7, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_7\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_7/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_7/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_7', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_7/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3591.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_7/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_7/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2564.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_7/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_7\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.242G     0.2993          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.242G      0.155          5         96: 100%|██████████| 196/196 [00:05<00:00, 36.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 111.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.242G     0.1509          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.14it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 99.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.242G     0.1166          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.97it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 95.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.242G     0.1067          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.69it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 96.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.242G     0.0849          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 105.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.242G    0.08289          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 133.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.242G    0.06513          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.75it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 106.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      0.25G    0.06333          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 116.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.258G    0.06531          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 107.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.016 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_7/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_7/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_7/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_7/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_7/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 76.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_7\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_7/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_7/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_7/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 78.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_72\u001b[0m\n",
            "Fold 7 completed in 64.15 seconds\n",
            "Fold 7 accuracy: 1.0000\n",
            "\n",
            "=== Fold 8/10 for original data ===\n",
            "  Fold 8 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_8, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_8, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_8\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_8/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_8/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_8', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_8/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3599.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_8/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_8/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2683.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_8/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_8\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.238G     0.3173          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.04it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 105.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.238G     0.1494          5         96: 100%|██████████| 196/196 [00:05<00:00, 35.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 128.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       0.98          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.238G     0.1298          5         96: 100%|██████████| 196/196 [00:05<00:00, 39.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 128.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.238G     0.1561          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.30it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 103.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.238G     0.1107          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 131.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.238G    0.08343          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 118.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.238G    0.08808          5         96: 100%|██████████| 196/196 [00:04<00:00, 40.27it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 113.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.238G    0.06785          5         96: 100%|██████████| 196/196 [00:04<00:00, 40.18it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.244G    0.07101          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.29it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 115.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.252G    0.05705          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 96.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_8/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_8/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_8/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_8/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_8/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 67.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_8\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_8/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_8/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_8/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 76.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          1          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_82\u001b[0m\n",
            "Fold 8 completed in 63.60 seconds\n",
            "Fold 8 accuracy: 1.0000\n",
            "\n",
            "=== Fold 9/10 for original data ===\n",
            "  Fold 9 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_9, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_9, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_9\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_9/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_9/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_9', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_9/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3598.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_9/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_9/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2557.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_9/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_9\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.242G     0.3146          5         96: 100%|██████████| 196/196 [00:06<00:00, 32.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.242G     0.1639          5         96: 100%|██████████| 196/196 [00:05<00:00, 36.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 130.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.242G     0.1255          5         96: 100%|██████████| 196/196 [00:05<00:00, 39.13it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 120.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.242G     0.1528          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.23it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 119.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.986          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.242G     0.1111          5         96: 100%|██████████| 196/196 [00:04<00:00, 40.01it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 111.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.242G    0.09222          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 112.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.988          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.242G    0.08417          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 126.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.242G    0.06969          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.92it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 115.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.244G    0.06219          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 104.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.252G    0.06578          5         96: 100%|██████████| 196/196 [00:04<00:00, 39.21it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 132.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.015 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_9/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_9/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_9/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_9/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_9/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 68.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.0ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_9\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_9/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_9/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_9/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 79.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_92\u001b[0m\n",
            "Fold 9 completed in 63.33 seconds\n",
            "Fold 9 accuracy: 0.9971\n",
            "\n",
            "=== Fold 10/10 for original data ===\n",
            "  Fold 10 - Train: 3125, Validation: 347\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/kfold_original/fold_10, epochs=10, time=None, patience=100, batch=16, imgsz=80, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/runs/kfold_original, name=fold_10, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/runs/kfold_original/fold_10\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_10/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_10/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n",
            "YOLOv8n-cls summary: 56 layers, 1,440,850 parameters, 1,440,850 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/runs/kfold_original/fold_10', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[80] must be multiple of max stride 32, updating to [96]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/kfold_original/fold_10/train... 3125 images, 0 corrupt: 100%|██████████| 3125/3125 [00:00<00:00, 3583.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/kfold_original/fold_10/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_10/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<00:00, 2655.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/kfold_original/fold_10/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 96 train, 96 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/kfold_original/fold_10\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      0.24G     0.3058          5         96: 100%|██████████| 196/196 [00:06<00:00, 31.91it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 91.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.977          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      0.24G     0.1498          5         96: 100%|██████████| 196/196 [00:05<00:00, 36.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 110.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      0.24G      0.138          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.84it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 130.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.983          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      0.24G     0.1251          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.22it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 117.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      0.24G     0.1164          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.00it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 133.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      0.24G    0.09939          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.02it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 113.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      0.24G    0.08483          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 106.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      0.24G    0.07606          5         96: 100%|██████████| 196/196 [00:05<00:00, 38.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 96.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.244G    0.07079          5         96: 100%|██████████| 196/196 [00:05<00:00, 37.49it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 101.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.994          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.252G    0.05027          5         96: 100%|██████████| 196/196 [00:05<00:00, 39.18it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 131.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.991          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.016 hours.\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_10/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from /content/runs/kfold_original/fold_10/weights/best.pt, 3.0MB\n",
            "\n",
            "Validating /content/runs/kfold_original/fold_10/weights/best.pt...\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_10/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_10/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "               classes   top1_acc   top5_acc: 100%|██████████| 11/11 [00:00<00:00, 72.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.1ms preprocess, 0.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_10\u001b[0m\n",
            "Ultralytics 8.3.103 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n",
            "YOLOv8n-cls summary (fused): 30 layers, 1,437,442 parameters, 0 gradients, 3.3 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/kfold_original/fold_10/train... found 3125 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/kfold_original/fold_10/val... found 347 images in 2 classes ✅ \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/kfold_original/fold_10/val... 347 images, 0 corrupt: 100%|██████████| 347/347 [00:00<?, ?it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 22/22 [00:00<00:00, 79.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all      0.997          1\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/kfold_original/fold_102\u001b[0m\n",
            "Fold 10 completed in 64.67 seconds\n",
            "Fold 10 accuracy: 0.9971\n",
            "\n",
            "=== ORIGINAL DATA K-FOLD RESULTS ===\n",
            "Mean accuracy: 0.9974\n",
            "Standard deviation: 0.0024\n",
            "Accuracy per fold: [0.9942528605461121, 0.9942528605461121, 0.9942362904548645, 1.0, 1.0, 0.9971181750297546, 1.0, 1.0, 0.9971181750297546, 0.9971181750297546]\n",
            "\n",
            "Best enhanced model: Fold 2 with accuracy 0.9971\n",
            "Best original model: Fold 4 with accuracy 1.0000\n",
            "\n",
            "Evaluating best model for enhanced data on the test set...\n",
            "Test Set Accuracy: 0.9948\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no-ship       1.00      0.99      1.00       286\n",
            "        ship       0.98      1.00      0.99       100\n",
            "\n",
            "    accuracy                           0.99       386\n",
            "   macro avg       0.99      1.00      0.99       386\n",
            "weighted avg       0.99      0.99      0.99       386\n",
            "\n",
            "Total test samples: 386\n",
            "Correct predictions: 384\n",
            "Misclassified samples: 2\n",
            "Saved misclassified samples to: /content/enhanced_misclassified.csv\n",
            "\n",
            "Evaluating best model for original data on the test set...\n",
            "Test Set Accuracy: 0.9974\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     no-ship       1.00      1.00      1.00       286\n",
            "        ship       0.99      1.00      1.00       100\n",
            "\n",
            "    accuracy                           1.00       386\n",
            "   macro avg       1.00      1.00      1.00       386\n",
            "weighted avg       1.00      1.00      1.00       386\n",
            "\n",
            "Total test samples: 386\n",
            "Correct predictions: 385\n",
            "Misclassified samples: 1\n",
            "Saved misclassified samples to: /content/original_misclassified.csv\n",
            "\n",
            "=== MODEL COMPARISON ===\n",
            "Enhanced Resolution Model:\n",
            "  - Cross-validation Accuracy: 0.9940 (±0.0033)\n",
            "  - Test Set Accuracy: 0.9948\n",
            "Original Resolution Model:\n",
            "  - Cross-validation Accuracy: 0.9974 (±0.0024)\n",
            "  - Test Set Accuracy: 0.9974\n",
            "\n",
            "Original resolution model performs 0.26% better on the test set.\n",
            "\n",
            "Complete evaluation process finished in 25.60 minutes\n",
            "\n",
            "K-fold validation complete! Check the output files for detailed results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "\n",
        "# Set style for better visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "\n",
        "def extract_metrics_from_csv(data_type, num_folds=10):\n",
        "    \"\"\"\n",
        "    Extract training and validation metrics from the results CSVs\n",
        "    generated by YOLOv8 during training.\n",
        "\n",
        "    Args:\n",
        "        data_type: 'enhanced' or 'original'\n",
        "        num_folds: Number of folds used in cross-validation\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with metrics for each fold\n",
        "    \"\"\"\n",
        "    all_fold_metrics = {}\n",
        "\n",
        "    for fold in range(1, num_folds + 1):\n",
        "        csv_path = f\"/content/runs/kfold_{data_type}/fold_{fold}/results.csv\"\n",
        "\n",
        "        if not os.path.exists(csv_path):\n",
        "            print(f\"Warning: Results CSV not found for {data_type} data, fold {fold}\")\n",
        "            continue\n",
        "\n",
        "        # Read results CSV\n",
        "        metrics_df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Store in dictionary\n",
        "        all_fold_metrics[fold] = metrics_df\n",
        "\n",
        "    return all_fold_metrics\n",
        "\n",
        "def plot_training_validation_curves(metrics_dict, data_type, metric_name=\"top1\"):\n",
        "    \"\"\"\n",
        "    Plot training vs validation curves for a specific metric across all folds.\n",
        "\n",
        "    Args:\n",
        "        metrics_dict: Dictionary with metrics dataframes for each fold\n",
        "        data_type: 'enhanced' or 'original'\n",
        "        metric_name: Name of the metric to plot (default is top1 for accuracy)\n",
        "\n",
        "    Returns:\n",
        "        None, saves the plot to disk\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # For storing mean values across folds\n",
        "    mean_train = None\n",
        "    mean_val = None\n",
        "    max_epochs = 0\n",
        "\n",
        "    # Plot each fold\n",
        "    for fold, df in metrics_dict.items():\n",
        "        if not f'train/{metric_name}' in df.columns or not f'val/{metric_name}' in df.columns:\n",
        "            print(f\"Warning: Metric {metric_name} not found in fold {fold}\")\n",
        "            continue\n",
        "\n",
        "        epochs = df['epoch'].values\n",
        "        train_values = df[f'train/{metric_name}'].values\n",
        "        val_values = df[f'val/{metric_name}'].values\n",
        "\n",
        "        # Update max epochs\n",
        "        max_epochs = max(max_epochs, len(epochs))\n",
        "\n",
        "        # Initialize mean arrays if needed\n",
        "        if mean_train is None:\n",
        "            mean_train = np.zeros(len(epochs))\n",
        "            mean_val = np.zeros(len(epochs))\n",
        "\n",
        "        # Update mean values\n",
        "        mean_train += train_values\n",
        "        mean_val += val_values\n",
        "\n",
        "        # Plot individual fold lines (lighter)\n",
        "        plt.plot(epochs, train_values, 'b-', alpha=0.2, label=f'Train Fold {fold}' if fold == 1 else \"\")\n",
        "        plt.plot(epochs, val_values, 'r-', alpha=0.2, label=f'Val Fold {fold}' if fold == 1 else \"\")\n",
        "\n",
        "    # Calculate and plot mean values\n",
        "    if mean_train is not None:\n",
        "        num_folds = len(metrics_dict)\n",
        "        mean_train /= num_folds\n",
        "        mean_val /= num_folds\n",
        "\n",
        "        plt.plot(epochs, mean_train, 'b-', linewidth=2, label='Mean Train')\n",
        "        plt.plot(epochs, mean_val, 'r-', linewidth=2, label='Mean Val')\n",
        "\n",
        "        # Calculate the gap between train and val at the last epoch\n",
        "        final_gap = mean_train[-1] - mean_val[-1]\n",
        "\n",
        "        # Add text annotation about overfitting\n",
        "        if final_gap > 0.05:  # Threshold for concerning gap\n",
        "            overfitting_level = \"High\" if final_gap > 0.1 else \"Moderate\"\n",
        "            plt.text(\n",
        "                max_epochs * 0.7,\n",
        "                0.3,\n",
        "                f\"Potential {overfitting_level} Overfitting\\nFinal Gap: {final_gap:.4f}\",\n",
        "                fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.8)\n",
        "            )\n",
        "        else:\n",
        "            plt.text(\n",
        "                max_epochs * 0.7,\n",
        "                0.3,\n",
        "                f\"Low Overfitting Risk\\nFinal Gap: {final_gap:.4f}\",\n",
        "                fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.8)\n",
        "            )\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel(f'{metric_name.capitalize()} Accuracy')\n",
        "    plt.title(f'Training vs Validation {metric_name.capitalize()} Accuracy - {data_type.capitalize()} Data')\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(f'/content/{data_type}_overfitting_check.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return mean_train, mean_val\n",
        "\n",
        "def plot_loss_curves(metrics_dict, data_type):\n",
        "    \"\"\"\n",
        "    Plot training vs validation loss curves across all folds.\n",
        "\n",
        "    Args:\n",
        "        metrics_dict: Dictionary with metrics dataframes for each fold\n",
        "        data_type: 'enhanced' or 'original'\n",
        "\n",
        "    Returns:\n",
        "        None, saves the plot to disk\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # For storing mean values across folds\n",
        "    mean_train_loss = None\n",
        "    mean_val_loss = None\n",
        "    max_epochs = 0\n",
        "\n",
        "    # Plot each fold\n",
        "    for fold, df in metrics_dict.items():\n",
        "        if not 'train/loss' in df.columns or not 'val/loss' in df.columns:\n",
        "            print(f\"Warning: Loss metrics not found in fold {fold}\")\n",
        "            continue\n",
        "\n",
        "        epochs = df['epoch'].values\n",
        "        train_loss = df['train/loss'].values\n",
        "        val_loss = df['val/loss'].values\n",
        "\n",
        "        # Update max epochs\n",
        "        max_epochs = max(max_epochs, len(epochs))\n",
        "\n",
        "        # Initialize mean arrays if needed\n",
        "        if mean_train_loss is None:\n",
        "            mean_train_loss = np.zeros(len(epochs))\n",
        "            mean_val_loss = np.zeros(len(epochs))\n",
        "\n",
        "        # Update mean values\n",
        "        mean_train_loss += train_loss\n",
        "        mean_val_loss += val_loss\n",
        "\n",
        "        # Plot individual fold lines (lighter)\n",
        "        plt.plot(epochs, train_loss, 'b-', alpha=0.2, label=f'Train Loss Fold {fold}' if fold == 1 else \"\")\n",
        "        plt.plot(epochs, val_loss, 'r-', alpha=0.2, label=f'Val Loss Fold {fold}' if fold == 1 else \"\")\n",
        "\n",
        "    # Calculate and plot mean values\n",
        "    if mean_train_loss is not None:\n",
        "        num_folds = len(metrics_dict)\n",
        "        mean_train_loss /= num_folds\n",
        "        mean_val_loss /= num_folds\n",
        "\n",
        "        plt.plot(epochs, mean_train_loss, 'b-', linewidth=2, label='Mean Train Loss')\n",
        "        plt.plot(epochs, mean_val_loss, 'r-', linewidth=2, label='Mean Val Loss')\n",
        "\n",
        "        # Calculate the gap between train and val loss at the last epoch\n",
        "        final_gap = mean_val_loss[-1] - mean_train_loss[-1]\n",
        "\n",
        "        # Add text annotation about overfitting\n",
        "        if final_gap > 0.1:  # Threshold for concerning gap\n",
        "            overfitting_level = \"High\" if final_gap > 0.2 else \"Moderate\"\n",
        "            plt.text(\n",
        "                max_epochs * 0.7,\n",
        "                mean_val_loss.max() * 0.7,\n",
        "                f\"Potential {overfitting_level} Overfitting\\nFinal Loss Gap: {final_gap:.4f}\",\n",
        "                fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.8)\n",
        "            )\n",
        "        else:\n",
        "            plt.text(\n",
        "                max_epochs * 0.7,\n",
        "                mean_val_loss.max() * 0.7,\n",
        "                f\"Low Overfitting Risk\\nFinal Loss Gap: {final_gap:.4f}\",\n",
        "                fontsize=12,\n",
        "                bbox=dict(facecolor='white', alpha=0.8)\n",
        "            )\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Training vs Validation Loss - {data_type.capitalize()} Data')\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc='upper right')\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig(f'/content/{data_type}_loss_curves.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    return mean_train_loss, mean_val_loss\n",
        "\n",
        "def plot_combined_metrics(enhanced_metrics, original_metrics):\n",
        "    \"\"\"\n",
        "    Plot a combined comparison of enhanced vs original data metrics\n",
        "\n",
        "    Args:\n",
        "        enhanced_metrics: Dict with metrics for enhanced data\n",
        "        original_metrics: Dict with metrics for original data\n",
        "\n",
        "    Returns:\n",
        "        None, saves the plot to disk\n",
        "    \"\"\"\n",
        "    # Extract mean accuracy curves\n",
        "    e_train_acc, e_val_acc = plot_training_validation_curves(enhanced_metrics, \"enhanced\", \"top1\")\n",
        "    o_train_acc, o_val_acc = plot_training_validation_curves(original_metrics, \"original\", \"top1\")\n",
        "\n",
        "    if e_train_acc is None or o_train_acc is None:\n",
        "        print(\"Warning: Cannot create combined plot due to missing data\")\n",
        "        return\n",
        "\n",
        "    # Create combined plot\n",
        "    plt.figure(figsize=(14, 10))\n",
        "\n",
        "    # Create x-axis for epochs\n",
        "    epochs = range(1, len(e_train_acc) + 1)\n",
        "\n",
        "    # Plot all curves\n",
        "    plt.plot(epochs, e_train_acc, 'b-', linewidth=2, label='Enhanced - Train Acc')\n",
        "    plt.plot(epochs, e_val_acc, 'b--', linewidth=2, label='Enhanced - Val Acc')\n",
        "    plt.plot(epochs, o_train_acc, 'g-', linewidth=2, label='Original - Train Acc')\n",
        "    plt.plot(epochs, o_val_acc, 'g--', linewidth=2, label='Original - Val Acc')\n",
        "\n",
        "    # Calculate overfitting gaps\n",
        "    enhanced_gap = e_train_acc[-1] - e_val_acc[-1]\n",
        "    original_gap = o_train_acc[-1] - o_val_acc[-1]\n",
        "\n",
        "    # Add text annotations about overfitting comparison\n",
        "    plt.text(\n",
        "        len(epochs) * 0.6,\n",
        "        0.4,\n",
        "        f\"Enhanced Data - Train/Val Gap: {enhanced_gap:.4f}\\nOriginal Data - Train/Val Gap: {original_gap:.4f}\",\n",
        "        fontsize=12,\n",
        "        bbox=dict(facecolor='white', alpha=0.8)\n",
        "    )\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Comparing Overfitting: Enhanced vs Original Resolution')\n",
        "    plt.ylim(0, 1.05)\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Save figure\n",
        "    plt.savefig('/content/resolution_comparison_overfitting.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def main():\n",
        "    # Extract metrics\n",
        "    enhanced_metrics = extract_metrics_from_csv('enhanced')\n",
        "    original_metrics = extract_metrics_from_csv('original')\n",
        "\n",
        "    # Check if we found metrics\n",
        "    if len(enhanced_metrics) == 0 and len(original_metrics) == 0:\n",
        "        print(\"No metrics found. Make sure training has completed and results.csv files exist.\")\n",
        "        return\n",
        "\n",
        "    # Plot accuracy curves\n",
        "    if len(enhanced_metrics) > 0:\n",
        "        print(\"Plotting enhanced data metrics...\")\n",
        "        plot_training_validation_curves(enhanced_metrics, 'enhanced')\n",
        "        plot_loss_curves(enhanced_metrics, 'enhanced')\n",
        "\n",
        "    if len(original_metrics) > 0:\n",
        "        print(\"Plotting original data metrics...\")\n",
        "        plot_training_validation_curves(original_metrics, 'original')\n",
        "        plot_loss_curves(original_metrics, 'original')\n",
        "\n",
        "    # If we have both types, create combined comparison\n",
        "    if len(enhanced_metrics) > 0 and len(original_metrics) > 0:\n",
        "        print(\"Creating combined comparison plot...\")\n",
        "        plot_combined_metrics(enhanced_metrics, original_metrics)\n",
        "\n",
        "    print(\"\\nPlotting complete! Check the following files for visualizations:\")\n",
        "    if len(enhanced_metrics) > 0:\n",
        "        print(\"- /content/enhanced_overfitting_check.png\")\n",
        "        print(\"- /content/enhanced_loss_curves.png\")\n",
        "    if len(original_metrics) > 0:\n",
        "        print(\"- /content/original_overfitting_check.png\")\n",
        "        print(\"- /content/original_loss_curves.png\")\n",
        "    if len(enhanced_metrics) > 0 and len(original_metrics) > 0:\n",
        "        print(\"- /content/resolution_comparison_overfitting.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTNieVQFqlWF",
        "outputId": "8ae82b08-f442-4f7e-8bac-37d0b96975bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting enhanced data metrics...\n",
            "Warning: Metric top1 not found in fold 1\n",
            "Warning: Metric top1 not found in fold 2\n",
            "Warning: Metric top1 not found in fold 3\n",
            "Warning: Metric top1 not found in fold 4\n",
            "Warning: Metric top1 not found in fold 5\n",
            "Warning: Metric top1 not found in fold 6\n",
            "Warning: Metric top1 not found in fold 7\n",
            "Warning: Metric top1 not found in fold 8\n",
            "Warning: Metric top1 not found in fold 9\n",
            "Warning: Metric top1 not found in fold 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-c248a87185b8>:123: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  plt.legend(loc='lower right')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting original data metrics...\n",
            "Warning: Metric top1 not found in fold 1\n",
            "Warning: Metric top1 not found in fold 2\n",
            "Warning: Metric top1 not found in fold 3\n",
            "Warning: Metric top1 not found in fold 4\n",
            "Warning: Metric top1 not found in fold 5\n",
            "Warning: Metric top1 not found in fold 6\n",
            "Warning: Metric top1 not found in fold 7\n",
            "Warning: Metric top1 not found in fold 8\n",
            "Warning: Metric top1 not found in fold 9\n",
            "Warning: Metric top1 not found in fold 10\n",
            "Creating combined comparison plot...\n",
            "Warning: Metric top1 not found in fold 1\n",
            "Warning: Metric top1 not found in fold 2\n",
            "Warning: Metric top1 not found in fold 3\n",
            "Warning: Metric top1 not found in fold 4\n",
            "Warning: Metric top1 not found in fold 5\n",
            "Warning: Metric top1 not found in fold 6\n",
            "Warning: Metric top1 not found in fold 7\n",
            "Warning: Metric top1 not found in fold 8\n",
            "Warning: Metric top1 not found in fold 9\n",
            "Warning: Metric top1 not found in fold 10\n",
            "Warning: Metric top1 not found in fold 1\n",
            "Warning: Metric top1 not found in fold 2\n",
            "Warning: Metric top1 not found in fold 3\n",
            "Warning: Metric top1 not found in fold 4\n",
            "Warning: Metric top1 not found in fold 5\n",
            "Warning: Metric top1 not found in fold 6\n",
            "Warning: Metric top1 not found in fold 7\n",
            "Warning: Metric top1 not found in fold 8\n",
            "Warning: Metric top1 not found in fold 9\n",
            "Warning: Metric top1 not found in fold 10\n",
            "Warning: Cannot create combined plot due to missing data\n",
            "\n",
            "Plotting complete! Check the following files for visualizations:\n",
            "- /content/enhanced_overfitting_check.png\n",
            "- /content/enhanced_loss_curves.png\n",
            "- /content/original_overfitting_check.png\n",
            "- /content/original_loss_curves.png\n",
            "- /content/resolution_comparison_overfitting.png\n"
          ]
        }
      ]
    }
  ]
}